{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46160e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantecon as qe\n",
    "from ast import literal_eval\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05947d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def creating_samples(samples_number, element):\n",
    "    gen=0\n",
    "    uniform_number = len(element)\n",
    "    uniform_samples = (-qe.simplex_grid(len(element), 1)+1)/(len(element)-1)\n",
    "    if samples_number > uniform_number:\n",
    "        random_samples = np.random.rand((samples_number-uniform_number), len(element))\n",
    "        for i in range(samples_number-uniform_number):\n",
    "            random_samples[i] = np.around(random_samples[i]/sum(random_samples[i]), decimals = 3)\n",
    "        sample = np.vstack((uniform_samples, random_samples))\n",
    "    else:\n",
    "        sample = uniform_samples[:samples_number]\n",
    "    samples = []\n",
    "    for i in range(samples_number):\n",
    "        samples.append(list(sample[i]))\n",
    "    samples = np.array(samples)\n",
    "    generation = []\n",
    "    for i in range (samples_number):\n",
    "            generation.append(gen)\n",
    "\n",
    "    ID = np.arange(1, (samples_number+1))\n",
    "\n",
    "    data = {'ID' : ID, 'Elements': [element], 'Generation': generation}\n",
    "    df = pd.DataFrame(data=data, index = np.arange(samples_number))\n",
    "    df = pd.concat([df, pd.DataFrame(([[i] for i in samples]), columns = ['Position'])], axis = 1)\n",
    "    df.to_csv(\"Result/Initial Population.txt\", sep='\\t', index=False, mode='w')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9694692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data and fitting\n",
    "df_old = pd.read_csv('Data/AuIrOsPdPtReRhRu_0.60_compositions_and_targets.csv')\n",
    "X_columns_old = ['Pt','Pd','Au','Ru','Rh','Ir','Re','Os']\n",
    "x_old = df_old[X_columns_old].to_numpy()\n",
    "y_old = df_old['current_over_capacitance'].to_numpy()\n",
    "\n",
    "#Rndom Forest Regression\n",
    "reg = RandomForestRegressor(n_estimators = 1024,\n",
    "                           bootstrap = True,\n",
    "                           max_depth = None,\n",
    "                           max_features = 'auto',\n",
    "                           min_samples_leaf = 1,\n",
    "                           min_samples_split = 2,\n",
    "                           oob_score = True)\n",
    "reg = reg.fit(x_old, y_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Class\n",
    "class pso:\n",
    "    def __init__ (self, data, step, target = np.array([0.333, 0.333, 0.333])):\n",
    "        self.datalog = data\n",
    "        #Reading \"Elements\" columns from string to list\n",
    "        self.datalog['Elements'] = self.datalog[\"Elements\"].apply(lambda x: literal_eval(x))\n",
    "        \n",
    "        #Select latest generation\n",
    "        self.generation = self.datalog['Generation'].max()\n",
    "        \n",
    "        #Creating np.array of \"Position\" column and dropping the string type \"Position\" column\n",
    "        self.position = []\n",
    "        for i in range(self.datalog['ID'].max()):\n",
    "            self.position.append(list(np.fromstring(self.datalog['Position'][i][1:-1], dtype=float, sep=' ')))\n",
    "        self.position = np.array(self.position)\n",
    "        self.datalog = self.datalog.drop(columns=['Position'])\n",
    "        self.datalog = pd.concat([self.datalog, pd.DataFrame(([[i] for i in self.position]), columns = ['Position'])], axis = 1)\n",
    "        \n",
    "        #Creating \"Velocity\" column for the \"0\" generation\n",
    "        if self.generation == 0:\n",
    "            self.velocity = np.around((-(self.position - target)/step), decimals = 3)\n",
    "            self.datalog = pd.concat([self.datalog, pd.DataFrame(([[i] for i in self.velocity]), columns = ['Velocity'])], axis = 1)\n",
    "        \n",
    "        #Creating blank \"Activity\" column\n",
    "        self.datalog = pd.concat([self.datalog, pd.DataFrame(columns = ['Activity'], index = np.arange(self.datalog['ID'].max()))], axis = 1)      \n",
    "\n",
    "        #Filling the \"Activity\" column with RFR\n",
    "        self.f_activity(self.position, self.datalog)\n",
    "            \n",
    "        #Creating dataframe of the latest generation\n",
    "        self.working_generation = self.datalog.loc[self.datalog['Generation']==self.generation]\n",
    "        \n",
    "\n",
    "    def move(self, size=1):\n",
    "        #Performing move function for certain number of times    \n",
    "        self.generation += 1\n",
    "        self.working_generation['Generation'] += 1 \n",
    "        \n",
    "        #Creating array of \"Position\" column\n",
    "        self.position_now = []\n",
    "        for i in range(self.working_generation['ID'].max()):\n",
    "            self.position_now.append(list(self.working_generation['Position'][i]))\n",
    "        self.position_now = np.array(self.position_now)\n",
    "        \n",
    "        #Moving process\n",
    "        self.position_now = np.around((self.position_now + self.velocity*size), decimals = 3)\n",
    "        for i in range(self.working_generation['ID'].max()):\n",
    "            \"\"\"if self.position_now[i].max() > 1 or self.position_now[i].min() < 0:\n",
    "                self.position_now[i] -= 2 * self.velocity[i]\"\"\"          \n",
    "            while self.position_now[i].max() > 1 or self.position_now[i].min() < 0:\n",
    "                self.position_now[i] = np.around((self.position_now[i]-self.velocity[i]), decimals = 3)\n",
    "            \n",
    "        #Creating dataframe\n",
    "        self.working_generation = self.working_generation.drop(columns=['Position'])\n",
    "        self.working_generation = pd.concat([self.working_generation, pd.DataFrame(([[i] for i in self.position_now]), columns = ['Position'])], axis = 1)\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        self.working_generation[]\n",
    "        for i in range(len(self.working_generation)):\n",
    "            if self.working_generation[\"Position\"][i].max() > 1 or self.working_generation[\"Position\"][i].min() < 0:\n",
    "                self.working_generation[\"Position\"][i] -= 2*self.working_generation['Velocity'][i]*size\"\"\"\n",
    "                \n",
    "        \n",
    "        #Filling the \"Activity\" column with RFR\n",
    "        self.f_activity(self.position_now, self.working_generation)\n",
    "        \n",
    "        #Concating the tables\n",
    "        self.datalog = pd.concat([self.datalog, self.working_generation])\n",
    "        self.store_datalog()\n",
    "        return\n",
    "    \n",
    "    def f_activity(self, x, dataframe):\n",
    "        global reg\n",
    "        a = [0, 0, 0, 0, 0]\n",
    "        self.dummy = []\n",
    "        for i in range(dataframe['ID'].max()):\n",
    "            self.dummy.append(np.hstack((x[i], a)))\n",
    "        self.activity = []\n",
    "        for i in range (dataframe['ID'].max()):\n",
    "            self.activity.append(float(reg.predict(np.reshape(self.dummy[i], (1, -1)))))\n",
    "        for i in range(dataframe['ID'].max()):\n",
    "            dataframe['Activity'][i] = self.activity[i]    \n",
    "        return\n",
    "\n",
    "    def store_datalog(self):\n",
    "        self.datalog.to_csv(\"Result/Initial Population_gen \"+str(self.generation)+\".txt\", sep='\\t', index=False, mode='w')\n",
    "        return\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105c574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_number = 6\n",
    "element = ['Pt', 'Pd', 'Au']\n",
    "creating_samples(samples_number, element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2188e5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 5\n",
    "target = np.array([0.9, 0.1, 0])\n",
    "population = pso(pd.read_csv('Result/Initial Population.txt', sep='\\t'), step, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0272ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "population.datalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc27b7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "population.move(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
